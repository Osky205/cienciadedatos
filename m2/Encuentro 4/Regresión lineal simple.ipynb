{"cells":[{"cell_type":"markdown","metadata":{"id":"Ye-G_YbkqbGb"},"source":["# Regresión Lineal\n"," \n","La regresión lineal es un modelo que trata de predecir variables numéricas como precios, cantidades, pesos, etc. Se basa en estimar el valor de la variable a predecir en función de las otras variables observadas.\n","\n","Es el modelo de regresión más básico. El objetivo es buscar la línea recta que mejor se ajuste a los datos conocidos. Esto se hace buscando la línea tal que la suma de las distancias de los datos a la línea sea mínima.\n","\n","Entrenar una regresión lineal, al igual que casi todos los modelos, es muy sencillo gracias a las bibliotecas disponibles en los diferentes lenguajes de programación. En este caso usaremos **pandas** y **scikit-learn**, una biblioteca de aprendizaje automático de software gratuito para Python.\n"," \n"]},{"cell_type":"markdown","metadata":{"id":"Ix8IWIcSP1k8"},"source":["## Parámetros e hiper parámetros\n"," \n","Cuando se va a entrenar un modelo es importante mantener en cuenta cuales son los parámetros y los hiperparámetros del mismo y la diferencia entre estos.\n"," \n","Los parámetros de un modelo son aquellos que se ajustan automáticamente en el entrenamiento del modelo, es decir, son aquellos valores que el modelo aprende para que la salida se asemeje a lo que queremos. En el caso de una regresión lineal, los parámetros son la pendiente de la recta y el intercepto, por ejemplo:\n"," \n","$Y = mX + b$\n"," \n","Los parámetros son $m$ y $b$.\n"," \n","Los hiperparámetros de un modelo son aquellos que escogemos, es decir, estos no se aprenden a través de los algoritmos de entrenamiento, sino que se **configuran previamente**. En el caso de la regresión lineal es posible definir si tiene o no un intercepto."]},{"cell_type":"markdown","metadata":{"id":"4bxKmjUVeOZB"},"source":["## Regresión Lineal Simple\n","\n","Comenzemos entrenando un modelo de regresión lineal simple, es decir que solamente tenga una variable predictora y una variable a predecir, en este caso utilizaremos un Dataset extraído de [Kaggle](https://www.kaggle.com/rsadiq/salary) que intentará predecir el salario en base a la antiguedad de un trabajador. \n","\n","Luego de la exploración y limpieza del Dataset, los pasos que realizaremos son: \n","\n","1. Dividir los datos en **X** (variables predictoras) e **y** (variable a predecir)\n","2. Dividir los datos en entrenamiento y testo con el método *train_test_split*\n","3. Importar e instanciar el modelo que utilizaremos y definir hiperparámetros\n","4. Entrenar el modelo con el método *fit*\n","5. Testear el modelo con el método *predict*\n","6. Evaluar la performance con una métrica "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g3yCux2WeOZC"},"outputs":[],"source":["#importamos las librerías que utilizaremos\n","\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns"]},{"cell_type":"markdown","metadata":{"id":"vanilla-enclosure"},"source":["#### Desde el Drive\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"higher-engineer"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"verified-listening"},"outputs":[],"source":["#Recordar utilizar dataset modificado de la clase pasada. \n","\n","data = pd.read_csv(\"/content/drive/MyDrive/Aprender Programando/2022/Guías y Recursos - Trayectos 2021/Recursos/Modulos 1 y 2. Presentación CABA/Ciencia de datos/2022/Módulo 2/Encuentro 4/salario.csv\")"]},{"cell_type":"markdown","metadata":{"id":"alien-connectivity"},"source":["#### Desde el archivo descargado en la computadora"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"convenient-agent"},"outputs":[],"source":["#from google.colab import files\n","#import io\n","\n","#filesUploaded = files.upload()   #Recordar utilizar el dataset de la clase pasada"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ruled-burlington"},"outputs":[],"source":["data = pd.read_csv(\"salario.csv\")"]},{"cell_type":"markdown","metadata":{"id":"oMob1iiqdyuj"},"source":["#### Exploración y limpieza del Dataset\n","\n","Realizaremos una pequeña exploración del dataset para confirmar qué variables tiene, si tiene datos nulos, si tiene datos numéricos, la distribución de las variables y la relación entre las mismas."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rpy6Wnd2eOZD"},"outputs":[],"source":["# Observamos los primeros registros del dataset\n","\n","data.head(3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5DWHwOjWeOZE"},"outputs":[],"source":["# vemos la información del dataset: cantidad de registros, tipos de dato y nulos\n","\n","data.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ADWF6zV0dyuk"},"outputs":[],"source":["# Vemos la distribución de las variables\n","\n","data.describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nNdaD0DoeOZF"},"outputs":[],"source":["# Vemos la correlación entre las variables, como se observa es alta\n","\n","data.corr()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vCawJcp3eOZF"},"outputs":[],"source":["# Realizamos un gráfico para observar la relación entre las variables\n","plt.figure(figsize = (10,10))\n","sns.scatterplot(data=data, x=\"anios_experiencia\", y=\"salario\", color = 'g')"]},{"cell_type":"markdown","metadata":{"id":"VBLVuUvieOZG"},"source":["#### División de datos en entrenamiento y testeo\n","\n","En primer lugar vamos a separar el Dataset para crear **X** e **y**:\n","- **X**: variables predictoras, en este caso *anios_experiencia*\n","- **y**: variable a predecir, en este caso *salario*\n","\n","Luego lo separaremos nuevamente entre datos de Entrenamiento y Testeo para lo cual usaremos [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html?highlight=train%20test%20split#sklearn.model_selection.train_test_split) de la librería de Scikit-learn. \n","\n","La función **train_test_split** debe recibir, un DataFrame solo con las variables a usar para predecir y, de forma separada, la columna objetivo, adicionalmente le podemos pasar otros parámetros, como la proporción de datos que queremos que tenga el conjunto de prueba (un valor entre 0 o 1) y el random_state, el cual nos permite que, al pasar los mismos datos, con el mismo valor de random_state, se hagan las separaciones iguales, con la finalidad de poder repetir el experimento.  \n","\n","Siempre importamos justo las funciones que requerimos de scikit-learn, esto lo hacemos ya que la librería es inmensa, con muchísimas funcionalidades y para mantener orden y limpieza en nuestro proyecto es recomendable hacer las importaciones de esta manera."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0m5jMx0weOZG"},"outputs":[],"source":["# División entre variables predictoras y variable a predecir\n","\n","X = data[\"anios_experiencia\"]\n","y = data[\"salario\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gwl_NZx2eOZG"},"outputs":[],"source":["# Confirmamos que se realizo correctamente observando X\n","\n","print(X.shape)\n","X.head(3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dvr20WuoeOZH"},"outputs":[],"source":["# Confirmamos que se realizo correctamente observando y\n","\n","print(y.shape)\n","y.head(3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s3XZjbx6eOZH"},"outputs":[],"source":["# Importamos train_test_split de la libreria scikit-learn\n","\n","from sklearn.model_selection import train_test_split "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xHeKCyZ0eOZH"},"outputs":[],"source":["# Definimos X de entrenamiento y de testeo e y de entrenamiento y testeo\n","\n","x_train, x_test, y_train, y_test = train_test_split(X,y, random_state=25)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UACVcNLteOZH"},"outputs":[],"source":["print(x_train.shape)\n","print(y_train.shape)\n","print(x_test.shape)\n","print(y_test.shape)"]},{"cell_type":"markdown","metadata":{"id":"lqyqNuMreOZI"},"source":["#### Entrenamiento del modelo\n","\n","En este caso en primer lugar importaremos e instanciaremos el modelo que utilizaremos, en este caso [regresion lineal](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) de la librería Scikit-Learn. \n","\n","Luego realizaremos el **entrenamiento** del modelo con el método *fit* y los **datos de entrenamiento**. El resultado será un modelo entrenado de regresión lineal de la cual podremos ver los parámetros: *pendiente de la recta* e *intercepto*(ordenada al origen).\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B0PkGmhveOZI"},"outputs":[],"source":["# Importamos el modelo que utilizaremos. Regresión lineal: \n","\n","from sklearn.linear_model import LinearRegression"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0AdlL0NkeOZI"},"outputs":[],"source":["# Definimos un objeto con el modelo importado, en este caso los hiperparametros son por default por lo que el parentesis está vacio\n","\n","modelo_rl = LinearRegression()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lppBj62YeOZI"},"outputs":[],"source":["#Necesita realizar esta operación para poder realizar el entrenamiento. Solo en el caso de regresión lineal simple (una sola variable predictora)\n","\n","import numpy as np\n","\n","X_train =x_train.to_numpy()\n","X_train = np.matrix(X_train.reshape(len(X_train),1))\n","\n","\n","X_test =x_test.to_numpy()\n","X_test = np.matrix(X_test.reshape(len(X_test),1))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H5GBHuMweOZI"},"outputs":[],"source":["# Realizamos el entrenamiento del modelo con el método fit y los datos de entrenamiento \n","\n","modelo_rl.fit(X_train, y_train)"]},{"cell_type":"markdown","metadata":{"id":"SZYWGAcUeOZJ"},"source":["##### Parámetros \n","\n","Los parámetros de una Regresión Lineal son el coeficiente (*pendiente de la recta*) y el intercepto (*ordenada al orignen*: *y* cuando *x=0*), en este caso se obtienden como resultado del entrenamiento del modelo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hvKveSmreOZJ"},"outputs":[],"source":["# Coeficiente (la pendiente de la recta)\n","\n","modelo_rl.coef_\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WeHmEW0beOZJ"},"outputs":[],"source":["# Intercepto (el punto de comienzo de la recta en el eje y)\n","\n","modelo_rl.intercept_"]},{"cell_type":"markdown","metadata":{"id":"_5DfvLt0eOZJ"},"source":["La forma de entender el modelo es que la recta que mejor se ajusta a los datos de entrenamiento es:\n","\n","> y = 20583.2 + x * 9303.95\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"gPHd_mY1eOZJ"},"source":["#### Testeo del modelo\n","\n","Ahora probaremos nuestro modelo, para eso utilizaremos el método *predict* con los datos de testeo (X_test) para que realice una predicción. Ese resultado lo compararemos con el resultado real (y_test) utilizando una métrica denominada R2 (que será explicada en profundidad la clase que viene).\n","\n","Observaremos con visualizaciionesón la regresión lineal resultado del entrenamiento del modelo y los datos de testeo y los datos totales (para las visualizaciones utilizaremos los datos antes de *reshape*, esto solo es para los casos de regresión lineal simple, es decir, una sola variable predictora)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D2KwsJlieOZK"},"outputs":[],"source":["# Probar el modelo con predict y los datos de test\n","\n","y_pred = modelo_rl.predict(X_test)\n","y_pred"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zU-tB0mseOZK"},"outputs":[],"source":["# La métrica que se utiliza para medir la performance de un modelo de regresión lineal es R2\n","\n","from sklearn.metrics import r2_score\n","r2 = r2_score(y_test,y_pred)\n","r2\n","\n","#Cuanto más cerca de 1 mejor el modelo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"barUSrWReOZK"},"outputs":[],"source":["#Visualizaciones de los datos de testeo\n","# La linea es el modelo (línea de regresión creada por el modelo) y los puntos son los datos de testeo (se usa X_train sin el reshape realizado)\n","\n","plt.figure(figsize = (10,10))\n","plt.plot(x_test, y_pred, color = 'b', label = 'Regresión lineal')\n","plt.scatter(x_test, y_test, color = 'g', label = 'Datos de testeo')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8wAr5OqEeOZK"},"outputs":[],"source":["# Visualización con los datos totales\n","# La linea es el modelo (línea de regresión creada por el modelo) y los puntos son los datos\n","\n","plt.figure(figsize = (10,10))\n","plt.plot(x_test, y_pred, color = 'b', label = 'Regresión lineal')\n","plt.scatter(X, y, color = 'g', label = 'Datos totales')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"ZbzoybcceOZK"},"source":["#### Hiperparámetros\n","\n","Un hiperparámetros es una variable que se define **antes** del entrenamiento **por el/la Científico/a de datos**.\n","\n","En la [documentación](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) de cada modelo se pueden ver los distintos hiperparámetros que se pueden definir.\n","\n","En la Regresión lineal simple un ejemplo de hiperparámetros es la existencia o no de un intercecpto\n","\n",">fit_intercept = *True* o *False* (por default True)\n","\n","Realizaremos los mismos pasos que el caso anterior para poder comparar los resultados. Utilizaremos los mismos datos de testeo y entrenamiento que en el modelo anterior por lo que los dos primeros pasos ya están realizados:\n","\n","1. Dividir los datos en **X** (variables predictoras) e **y** (variable a predecir)\n","2. Dividir los datos en entrenamiento y testo con el mètodo *train_test_split*\n","3. Importar e instanciar el modelo que utilizaremos y definir hiperparámetros\n","4. Entrenar el modelo con el método *fit*\n","5. Testear el modelo con el método *predict*\n","6. Ver la performance con una métrica y comparar los distintos modelos entrenados\n","\n","Luego visualizaremos los dos modelos entrenados con los datos de testeo y con los datos totales."]},{"cell_type":"markdown","metadata":{"id":"C3ahGz1Rdyup"},"source":["##### Instanciar y entrenar el modelo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dDgIFYRjeOZK"},"outputs":[],"source":["# Al momento de instanciar el modelo se definen los hiperparámetros\n","\n","modelo_sin_inter = LinearRegression(fit_intercept = False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zGqaZ5uheOZL"},"outputs":[],"source":["# Se entena el modelo sin intercepto (se usa x_train con el reshape ya realizado)\n","\n","modelo_sin_inter.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x21lnH79eOZL"},"outputs":[],"source":["# El coeficiente del modelo (la pendiente de la recta)\n","\n","modelo_sin_inter.coef_"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"24FQkHG7eOZL"},"outputs":[],"source":["# El intercepto es 0 debido a que eso es lo que se ha definido\n","\n","modelo_sin_inter.intercept_"]},{"cell_type":"markdown","metadata":{"id":"o1hjIT2Xdyuq"},"source":["##### Probar el modelo y medir la performance"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eiadR7NYeOZL"},"outputs":[],"source":["# Probar nuestro modelo con los datos de test\n","\n","y_pred_sin_inter = modelo_sin_inter.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8SpxSS3QeOZL"},"outputs":[],"source":["# La métrica que se utiliza para medir un modelo de regresión lineal es R2\n","\n","from sklearn.metrics import r2_score\n","r2_sin_interc = r2_score(y_test,y_pred_sin_inter)\n","r2_sin_interc\n","\n","#Cuanto más cerca de 1 mejor el modelo."]},{"cell_type":"markdown","metadata":{"id":"JO0YZP3Odyuq"},"source":["##### Comparar la performance de ambos modelos entrenados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q03sYc_qeOZL"},"outputs":[],"source":["# Es muy bueno pero levemente peor que el anterior\n","\n","print(\"el R2 del modelo con intercepto es \", round(r2,2))\n","print(\"el R2 del modelo sin intercepto es \", round(r2_sin_interc,2))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t0IGuq0XeOZM"},"outputs":[],"source":["#Visualizaciones de los modelos con los datos de testeo\n","# Los puntos verdes son los datos de testeo, la línea azul es el modelo y la linea roja es el modelo sin intercepto\n","\n","plt.figure(figsize = (10,10))\n","plt.plot(x_test, y_pred, color = 'b',linewidth=3.0,  linestyle = \"--\", label = 'Regresión lineal')\n","plt.plot(x_test, y_pred_sin_inter, color = 'r',linewidth=3.0,  linestyle = \":\" , label = 'Regresión lineal sin intercepto')\n","plt.scatter(x_test, y_test, color = 'g', label = 'Datos de testeo')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PhMC8jUaXUfd"},"outputs":[],"source":["#Visualizaciones de los modelos con los datos totales\n","# Los puntos verdes son los datos de testeo, la línea azul es el modelo y la linea roja es el modelo sin intercepto\n","\n","plt.figure(figsize = (10,10))\n","plt.plot(x_test, y_pred, color = 'b',linewidth=3.0,  linestyle = \"--\", label = 'Regresión lineal')\n","plt.plot(x_test, y_pred_sin_inter, color = 'r',linewidth=3.0,  linestyle = \":\" , label = 'Regresión lineal sin intercepto')\n","plt.scatter(X, y, color = 'g', label = 'Datos totales')\n","plt.legend()\n","plt.show()"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Regresión lineal simple.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"}},"nbformat":4,"nbformat_minor":0}